{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b275ec2-c78f-4fe4-bd22-acc063ac8ecb",
   "metadata": {},
   "source": [
    "# Encoder decoder chapter notes\n",
    "This type of model is actually two models in one. Given a variable length input, one half of the model transforms that into a meaningful fixed length vector, and that is then fed into the traditional LSTM we know and love. The book discusses some strange shinanigans about how it was used for natural language processing, and a huge improvement to the model was feeding the input in backwards??? That was very strange. I didn't understand that one bit. \n",
    "\n",
    "The structure of this is similar to the CNN_LSTM<br>\n",
    "Input --> Encoder --> Decoder --> Dense --> Output\n",
    "\n",
    "### Uses\n",
    "* Translating languages\n",
    "* Predicting code execution\n",
    "* Image captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6633734d-6e5b-4936-85a8-15e054ac7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 20:33:33.111421: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-01 20:33:33.111452: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Necessary neural net imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "# Necessary number manip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random as rand\n",
    "\n",
    "# Necessary plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# I also want to hide stinky warning boxes, and \n",
    "# this: https://stackoverflow.com/questions/9031783/hide-all-warnings-in-ipython\n",
    "# had some solutions.\n",
    "def hide_warnings():\n",
    "    from IPython.display import HTML\n",
    "    HTML('''<script>\n",
    "    var code_show_err = false; \n",
    "    var code_toggle_err = function() {\n",
    "     var stderrNodes = document.querySelectorAll('[data-mime-type=\"application/vnd.jupyter.stderr\"]')\n",
    "     var stderr = Array.from(stderrNodes)\n",
    "     if (code_show_err){\n",
    "         stderr.forEach(ele => ele.style.display = 'block');\n",
    "     } else {\n",
    "         stderr.forEach(ele => ele.style.display = 'none');\n",
    "     }\n",
    "     code_show_err = !code_show_err\n",
    "    } \n",
    "    document.addEventListener('DOMContentLoaded', code_toggle_err);\n",
    "    </script>\n",
    "    To toggle on/off output_stderr, click <a onclick=\"javascript:code_toggle_err()\">here</a>.''')\n",
    "    \n",
    "hide_warnings()\n",
    "###########################################################\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e6391-0d90-446f-b16e-7732f93a2888",
   "metadata": {},
   "source": [
    "---\n",
    "O ho! On page 128 I get a clue to the way ```TimeDistributed``` works!!!\n",
    "> The same weights can\n",
    "be used to output each time step in the output sequence by wrapping the ```Dense``` layer in a\n",
    "```TimeDistributed``` wrapper.\n",
    "\n",
    "It somehow lets the weights not change with every output????\n",
    "\n",
    "---\n",
    "\n",
    "We have an issue, the encoder will not output a properly shaped array that will fit onto the decoder nicely. To get around this, we can use the ```RepeatVector``` layer as an adapter. \n",
    "\n",
    "# Defining the Addition Prediction Problem\n",
    "If I write 10+6= I would expect 16. So in total I would have \"10+6=16\". For the computer I can define this as \n",
    "```\n",
    "Input: ['1', '0', '+', '6']\n",
    "Output: ['1', '6']\n",
    "```\n",
    "\n",
    "I imagine this data generation is going to be the hardest part!\n",
    "\n",
    "### random_sum_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a9486e-d2cd-4204-9d58-c27f5be0f5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2, 5]], [7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_sum_pairs(n_examples, largest_n, n_summation):\n",
    "    '''\n",
    "    Given:\n",
    "    * n_examples: How many examples we want to generate\n",
    "    * largest_n: The largest number we want\n",
    "    * n_summation: the number of numbers we will be summing\n",
    "    \n",
    "    Output:\n",
    "    * X: [[1,2,...n_summation],[largest_n, 2, ...],...n_examples]\n",
    "    * y: [m, l,...n_examples]\n",
    "    '''\n",
    "    X, y = list(), list()\n",
    "    for _ in range(n_examples):\n",
    "        left_side = [rand.randint(1,largest_n) for _ in range(n_summation)]\n",
    "        right_side = sum(left_side)\n",
    "        X.append(left_side)\n",
    "        y.append(right_side)\n",
    "    return X,y\n",
    "\n",
    "# Well this works well :)\n",
    "random_sum_pairs(1, 10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd33d25-a72b-4828-8b87-0f010fd53d94",
   "metadata": {},
   "source": [
    "The book now says we need to turn these into padded strings. Well lets first think on how we will do this. We need to ensure that we don't run out of space, and yet don't create too much padding. We can figure out how much space a number will take up via ```floor(log10(largest_n)+1)```. For example plugging 32 will give us 2 digits, 100 will give us 3, etc. Now we can multiply that by ```n_summation```, and add ```n_summation-1``` (for the operation character). The full formula for length would be<br>\n",
    "**INPUT**\n",
    "> ```max_left = n_summation * np.floor(np.log10(largest_n)+1) + (n_summation-1)```\n",
    "\n",
    "**OUTPUT**\n",
    "> ```max_right =  np.floor(np.log10(n_summation * largest_n)+1)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44719dfa-f3f1-418d-ac44-4529980077aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input:  8.0\n",
      "Max output:  3.0\n"
     ]
    }
   ],
   "source": [
    "n_summation=3\n",
    "largest_n=50\n",
    "max_len = n_summation * np.floor(np.log10(largest_n)+1) + (n_summation-1); print(\"Max input: \",max_len)\n",
    "max_right = np.floor(np.log10(n_summation * largest_n)+1); print(\"Max output: \", max_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0929a-b838-497d-a1e1-1c3d637e9649",
   "metadata": {},
   "source": [
    "### to_string(X,y,n_summation,largest_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26e42a52-3178-429c-860c-d725876b19cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 1]] [10]\n"
     ]
    }
   ],
   "source": [
    "def to_string(X_num,y_num,n_summation,largest_n):\n",
    "    X,y = list(), list()\n",
    "    max_left = n_summation * np.floor(np.log10(largest_n)+1) + (n_summation-1)\n",
    "    max_right = np.floor(np.log10(n_summation * largest_n)+1)\n",
    "    for X_pattern, y_pattern in zip(X_num, y_num):\n",
    "        # X padding\n",
    "        X_str = \"+\".join([str(value) for value in X_pattern])\n",
    "        X_pad = \" \"*int(max_left-len(X_str))\n",
    "        X.append(X_pad+X_str)\n",
    "        \n",
    "        # y padding\n",
    "        y_str = str(y_pattern)\n",
    "        y_pad = \" \"*int(max_right-len(y_str))\n",
    "        y.append(y_pad+y_str)\n",
    "    return X,y\n",
    "        \n",
    "n_examples = 1\n",
    "n_summation = 2\n",
    "largest_n = 10\n",
    "X,y = random_sum_pairs(n_examples, largest_n, n_summation)\n",
    "print(X,y)\n",
    "X,y = to_string(X,y,n_summation,largest_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21e1f187-0d17-43a6-89fa-a7e2775f2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(sequence, categories=None):\n",
    "    '''\n",
    "    Given a list \"sequence\" return it one-hot encoded\n",
    "    This automatically finds all the unique values in\n",
    "    the input and makes them the categories. Requires\n",
    "    numpy and pandas as imports\n",
    "    Usage: make_dummies([1,5,6])\n",
    "    Returns an np array: \n",
    "    array([[1, 0, 0],\n",
    "           [0, 1, 0],\n",
    "           [0, 0, 1]], dtype=uint8)\n",
    "    '''\n",
    "    if not categories:\n",
    "        categories = set(np.array(sequence).flatten())\n",
    "    sequence = pd.DataFrame(sequence,\n",
    "                            dtype=pd.CategoricalDtype(categories=categories))\n",
    "    sequence = pd.get_dummies(sequence)\n",
    "    return np.array(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c1903e6-3595-4ad2-8d57-4fd196e0fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9+1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [str(x) for x in range(0,10)]\n",
    "categories.append('+')\n",
    "categories.append(' ')\n",
    "print(X[0])\n",
    "make_dummies(list(X[0]), categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f0c8f01-29d0-4b41-8a95-f547165de809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 6+10']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c38ee2ca-a6e2-4108-a4e1-e14c5412e07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 6+10']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf86c25-0713-4daf-ac6d-36e92cb8ebbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
